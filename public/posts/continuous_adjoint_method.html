<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Continuous Adjoint Method</title>
<meta name="author" content="Mag√≠ Romany√† Serrasolsas" />
<meta name="generator" content="Org Mode" />
<link rel='icon' href='data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üçÖ</text></svg>'>
      <meta name='viewport' content='width=device-width, initial-scale=1'>
      <link rel='stylesheet' href='https://code.cdn.mozilla.net/fonts/fira.css'>
      <link rel='stylesheet' href='/css/site.css' type='text/css'/>
      <link rel='stylesheet' href='/css/syntax-coloring.css' type='text/css'/>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="/"> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="preamble" class="status">
<div class='intro'>
  <img src='../resources/profile.jpg' alt='Mag√≠ Romany√† class='no-border'/>
  <h1>
    <a href='/'>
    <span class="gray">Mag√≠</span>
    <span class="black">Romany√†</span>
    </a>
  </h1>
  <p>Computer Graphics PhD student</p>
</div>

<div class='nav'>
<ul>
<li><a href='/'>
    <svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 1792 1792"><path fill="currentColor" d="M1523 1339q-22-155-87.5-257.5T1251 963q-67 74-159.5 115.5T896 1120t-195.5-41.5T541 963q-119 16-184.5 118.5T269 1339q106 150 271 237.5t356 87.5t356-87.5t271-237.5m-243-699q0-159-112.5-271.5T896 256T624.5 368.5T512 640t112.5 271.5T896 1024t271.5-112.5T1280 640m512 256q0 182-71 347.5t-190.5 286T1245 1721t-349 71q-182 0-348-71t-286-191t-191-286T0 896t71-348t191-286T548 71T896 0t348 71t286 191t191 286t71 348"/></svg>
    About</a>.</li>
<li><a href='http://github.com/magiromanya'>
    <svg xmlns="http://www.w3.org/2000/svg" width="1.03em" height="1em" viewBox="0 0 1536 1504"><path fill="currentColor" d="M768 0q209 0 385.5 103T1433 382.5T1536 768q0 251-146.5 451.5T1011 1497q-27 5-40-7t-13-30q0-3 .5-76.5t.5-134.5q0-97-52-142q57-6 102.5-18t94-39t81-66.5t53-105T1258 728q0-119-79-206q37-91-8-204q-28-9-81 11t-92 44l-38 24q-93-26-192-26t-192 26q-16-11-42.5-27T450 331.5T365 318q-45 113-8 204q-79 87-79 206q0 85 20.5 150T351 983t80.5 67t94 39t102.5 18q-39 36-49 103q-21 10-45 15t-57 5t-65.5-21.5T356 1146q-19-32-48.5-52t-49.5-24l-20-3q-21 0-29 4.5t-5 11.5t9 14t13 12l7 5q22 10 43.5 38t31.5 51l10 23q13 38 44 61.5t67 30t69.5 7t55.5-3.5l23-4q0 38 .5 88.5t.5 54.5q0 18-13 30t-40 7q-232-77-378.5-277.5T0 768q0-209 103-385.5T382.5 103T768 0M291 1103q3-7-7-12q-10-3-13 2q-3 7 7 12q9 6 13-2m31 34q7-5-2-16q-10-9-16-3q-7 5 2 16q10 10 16 3m30 45q9-7 0-19q-8-13-17-6q-9 5 0 18t17 7m42 42q8-8-4-19q-12-12-20-3q-9 8 4 19q12 12 20 3m57 25q3-11-13-16q-15-4-19 7t13 15q15 6 19-6m63 5q0-13-17-11q-16 0-16 11q0 13 17 11q16 0 16-11m58-10q-2-11-18-9q-16 3-14 15t18 8t14-14"/></svg>
    GitHub</a>.</li>
<!-- <li><a href='https://www.reddit.com/user/'>Reddit</a>.</li> -->
<li><a href='/rss.xml'>
    <svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 1536 1536"><path fill="currentColor" d="M512 1152q0-53-37.5-90.5T384 1024t-90.5 37.5T256 1152t37.5 90.5T384 1280t90.5-37.5T512 1152m351 94q-13-233-176.5-396.5T290 673q-14-1-24 9t-10 23v128q0 13 8.5 22t21.5 10q154 11 264 121t121 264q1 13 10 21.5t22 8.5h128q13 0 23-10t9-24m384 1q-5-154-56-297.5t-139.5-260t-205-205t-260-139.5T289 289q-14-1-23 9q-10 10-10 23v128q0 13 9 22t22 10q204 7 378 111.5T943.5 871t111.5 378q1 13 10 22t22 9h128q13 0 23-10q11-9 9-23m289-959v960q0 119-84.5 203.5T1248 1536H288q-119 0-203.5-84.5T0 1248V288Q0 169 84.5 84.5T288 0h960q119 0 203.5 84.5T1536 288"/></svg>
    RSS</a>.</li>
<li><a href='/posts/sitemap.html'>
    <svg xmlns="http://www.w3.org/2000/svg" width="0.88em" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M162.4 196c4.8-4.9 6.2-5.1 36.4-5.1c27.2 0 28.1.1 32.1 2.1c5.8 2.9 8.3 7 8.3 13.6c0 5.9-2.4 10-7.6 13.4c-2.8 1.8-4.5 1.9-31.1 2.1c-16.4.1-29.5-.2-31.5-.8c-10.3-2.9-14.1-17.7-6.6-25.3m61.4 94.5c-53.9 0-55.8.2-60.2 4.1c-3.5 3.1-5.7 9.4-5.1 13.9c.7 4.7 4.8 10.1 9.2 12c2.2 1 14.1 1.7 56.3 1.2l47.9-.6l9.2-1.5c9-5.1 10.5-17.4 3.1-24.4c-5.3-4.7-5-4.7-60.4-4.7m223.4 130.1c-3.5 28.4-23 50.4-51.1 57.5c-7.2 1.8-9.7 1.9-172.9 1.8c-157.8 0-165.9-.1-172-1.8c-8.4-2.2-15.6-5.5-22.3-10c-5.6-3.8-13.9-11.8-17-16.4c-3.8-5.6-8.2-15.3-10-22C.1 423 0 420.3 0 256.3C0 93.2 0 89.7 1.8 82.6C8.1 57.9 27.7 39 53 33.4c7.3-1.6 332.1-1.9 340-.3c21.2 4.3 37.9 17.1 47.6 36.4c7.7 15.3 7-1.5 7.3 180.6c.2 115.8 0 164.5-.7 170.5m-85.4-185.2c-1.1-5-4.2-9.6-7.7-11.5c-1.1-.6-8-1.3-15.5-1.7c-12.4-.6-13.8-.8-17.8-3.1c-6.2-3.6-7.9-7.6-8-18.3c0-20.4-8.5-39.4-25.3-56.5c-12-12.2-25.3-20.5-40.6-25.1c-3.6-1.1-11.8-1.5-39.2-1.8c-42.9-.5-52.5.4-67.1 6.2c-27 10.7-46.3 33.4-53.4 62.4c-1.3 5.4-1.6 14.2-1.9 64.3c-.4 62.8 0 72.1 4 84.5c9.7 30.7 37.1 53.4 64.6 58.4c9.2 1.7 122.2 2.1 133.7.5c20.1-2.7 35.9-10.8 50.7-25.9c10.7-10.9 17.4-22.8 21.8-38.5c3.2-10.9 2.9-88.4 1.7-93.9"/></svg>
    Blog</a></li>
</ul>
</div>
</div>
<div id="content" class="content">
<h1 class="title">Continuous Adjoint Method
<br />
<span class="subtitle">Published on 16 Nov, 2023 by Mag√≠ Romany√† Serrasolsas.</span>
</h1>

<div id="outline-container-org35f66fc" class="outline-2">
<h2 id="org35f66fc"><a href="#org35f66fc">Introduction</a></h2>
<div class="outline-text-2" id="text-org35f66fc">
<p>
In my master thesis, I've been working in propagating adjoints backwards, which looked like the discretization of solving an ODE in reverse.
In this article, we are going to see that in fact, when using the back propagation algorithm, covered in this <a href="differential_simulation.html">article</a>, we are solving an ODE.
Also we are going to derive how does this ODE look like.
The work shown in this article relies heavily on the excellent Standford tutorial found <a href="https://cs.stanford.edu/~ambrad/adjoint_tutorial.pdf">here</a>.
</p>
</div>
</div>

<div id="outline-container-orgb58d292" class="outline-2">
<h2 id="orgb58d292"><a href="#orgb58d292">The problem setting</a></h2>
<div class="outline-text-2" id="text-orgb58d292">
<p>
First we are going to write down our notation and describe the problem we want to solve.
Analytically, solving a forward simulation, is equivalent as integrating a certain differential equation.
</p>
\begin{equation}
\label{eq:ode}
\newcommand{\totald}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\partiald}[2]{\frac{\partial#1}{\partial#2}}
\totald{\mathbf{s}}{t} = \mathbf{\hat{f}}(\mathbf{s}, \mathbf{p}, t)
,\quad \mathbf{s}(0)=\mathbf{s}_0
\end{equation}

<p>
To formulate our back propagation of adjoint states also as an ODE, we are going to need a description of the objective function.
The objective function in the continuous case is no longer a function but a functional.
It does not take variables as an input but whole functions, in this case is going to depend on the function \(\mathbf{s}(\mathbf{p},t)\).
</p>

\begin{equation}
\Phi(\mathbf{s}, \mathbf{p}) = \int_{0}^{T}\phi(\mathbf{s}, \mathbf{p}, t)\mathrm{d}t
\end{equation}

<p>
We can think of this integral as evaluating our function \(\mathbf{s}(t)\) at each point in time between 0 and \(T\), and feeding this result to an "instantaneous objective function" \(\phi\), and then summing all the results.
</p>

<p>
With all this formulation, we can finally write our minimization problem with constraints as:
</p>
\begin{equation}
\label{eq:minimization}
\arg \min_{\mathbf{p}} \Phi(\mathbf{s}, \mathbf{p}), \quad \text{subject to}
\begin{cases}
\mathbf{f}(\mathbf{s}, \totald{\mathbf{s}}{t}, \mathbf{p}, t) = 0 \\
\mathbf{g}(\mathbf{s}(0), \mathbf{s}_0) = 0
\end{cases}
\end{equation}
<p>
Where the \(\mathbf{f}\) and \(\mathbf{g}\) functions are the ODE and the initial conditions described in equation \eqref{eq:ode}, written in implicit form, \(\mathbf{f} \equiv \frac{\mathrm{d}\mathbf{s}}{\mathrm{d}t} - \mathbf{\hat{f}}\), \(\mathbf{g} \equiv \mathbf{s}(0) - \mathbf{s}_0\).
</p>
</div>
</div>

<div id="outline-container-orgc42eeba" class="outline-2">
<h2 id="orgc42eeba"><a href="#orgc42eeba">Solving the minimization problem</a></h2>
<div class="outline-text-2" id="text-orgc42eeba">
<p>
Now that we have the formulation of the problem, we can start solving it.
The problem is formally known as a minimization with constraints and can be approached using lagrange multipliers.
The first step towards solving the problem is to introduce the Lagrangian, with no constraints, which in this case is nothing more than our objective function:
</p>
\begin{equation}
\mathcal{L} = \Phi = \int_{0}^{T}\phi(\mathbf{s}, \mathbf{p}, t)\mathrm{d}t
\end{equation}

<p>
Now we want to introduce the constraints to this equation using Lagrange multipliers that we will define as the \(\lambda\) and \(\mu\) vectors.
</p>

\begin{equation}
\mathcal{L} = \int_{0}^{T}\left[\phi(\mathbf{s}, \mathbf{p}, t) + \lambda^T\mathbf{f}(\mathbf{s}, \totald{\mathbf{s}}{t}, \mathbf{p}, t) \right]\mathrm{d}t +
 \mu^T\mathbf{g}(\mathbf{s}(0), \mathbf{s}_0)
\end{equation}
<p>
Note that this holds because we have defined the \(\mathbf{f}\) and \(\mathbf{g}\) functions to be equal to zero in the formulation of the problem shown in \eqref{eq:minimization}.
Also this holds for any \(\lambda\) and \(\mu\), which means that we have the freedom to choose this Lagrange multipliers.
</p>

<p>
From here we will take the derivative of this Lagrangian with respect to the simulation parameters \(p\).
</p>
\begin{equation}
\label{eq:lagrangian-derivative}
\begin{split}
\totald{\mathcal{L}}{\mathbf{p}} = \int_{0}^{T}\left[
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{p}} +
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{s}}\totald{\mathbf{s}}{\mathbf{p}} +
\lambda^T\left(
\partiald{\mathbf{f}}{\mathbf{p}} +
\partiald{\mathbf{f}}{\mathbf{s}}\totald{\mathbf{s}}{\mathbf{p}} +
\partiald{\mathbf{f}}{\mathbf{\dot{s}}}\totald{\mathbf{\dot{s}}}{\mathbf{p}}
\right)\right]\mathrm{d}t \\ +
\mu^T\left(
\partiald{\mathbf{g}}{\mathbf{p}} +
\partiald{\mathbf{g}}{\mathbf{s}(0)}\totald{\mathbf{s}(0)}{\mathbf{p}}
\right)
\end{split}
\end{equation}

<p>
In this step we have applied the chain rule to all the functions present. Also we introduced the notation \(\mathbf{\dot{s}}\equiv\totald{\mathbf{s}}{t}\) to make the equation cleaner.
Now it is possible to write the term containing \(\totald{\mathbf{\dot{s}}}{\mathbf{p}}\) in terms of the derivative \(\totald{\mathbf{s}}{\mathbf{p}}\) by integrating by parts:
</p>
\begin{equation}
\int_0^T\lambda^T
\partiald{\mathbf{f}}{\mathbf{\dot{s}}}\totald{\mathbf{\dot{s}}}{\mathbf{p}}
\mathrm{d}t =
\left.\lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}\totald{\mathbf{s}}{\mathbf{t}}\right|_0^T
-\int_0^T\left(
\totald{\lambda^T}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}} +
\lambda^T\totald{}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)\totald{\mathbf{s}}{\mathbf{p}}
\mathrm{d}t
\end{equation}

<p>
Substituting this result into the Lagrangian derivative expression in \eqref{eq:lagrangian-derivative}, and grouping all the terms with the derivative \(\totald{\mathbf{s}}{\mathbf{p}}\), we can write:
</p>
\begin{equation}
\label{eq:lagrangian-derivative2}
\begin{split}
\totald{\mathcal{L}}{\mathbf{p}} = \int_{0}^{T}\left[
\left(
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{s}} +
\lambda^T\left(
\partiald{\mathbf{f}}{\mathbf{s}} -
\totald{}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)-
\totald{\lambda^T}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)
\totald{\mathbf{s}}{\mathbf{p}} +
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{p}} +
\lambda^T\partiald{\mathbf{f}}{\mathbf{p}}
\right]\mathrm{d}t +\\
\left.\lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}\totald{\mathbf{s}}{\mathbf{t}}\right|_T +
\left.\left(
\mu^T\partiald{\mathbf{g}}{\mathbf{s}(0)}
- \lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)\right|_0
\totald{\mathbf{s}(0)}{\mathbf{p}} +
\mu^T
\partiald{\mathbf{g}}{\mathbf{p}}
\end{split}
\end{equation}

<p>
This is one ugly expression, and a lot is going on.
Fortunately, we have still some freedom to deal with, as we have yet to fix our Lagrange multipliers \(\lambda\) and \(\mu\).
It is our main interest to avoid computing the sensitivity matrix \(\totald{\mathbf{s}}{\mathbf{p}}\), so we will choose our multipliers to cancel the terms where they appear.
</p>
\begin{align}
\left.\lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}\totald{\mathbf{s}}{\mathbf{t}}\right|_T &= 0 \\
\left.\left(
\mu^T\partiald{\mathbf{g}}{\mathbf{s}(0)}
- \lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)\right|_0 &= 0 \\
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{s}} +
\lambda^T\left(
\partiald{\mathbf{f}}{\mathbf{s}} -
\totald{}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)-
\totald{\lambda^T}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
&= 0
\end{align}

<p>
From the first equation, we can take \(\lambda(T) = 0\), which is a initial conditions equation. And from the second equation we can take \(\mu^T = \lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}{\left(\partiald{\mathbf{g}}{\mathbf{s}(0)}\right)}^{-1}\).
Finally, from the last equation, we can write the following ODE that the \(\lambda\) multiplier has to fulfill.
</p>
\begin{equation}
\totald{\lambda^T}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
=
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{s}} +
\lambda^T\left(
\partiald{\mathbf{f}}{\mathbf{s}} -
\totald{}{t}\partiald{\mathbf{f}}{\mathbf{\dot{s}}}
\right)
\end{equation}

<p>
With these defined multipliers our Lagrangian gradient can be written in a nicer expression:
</p>
\begin{equation}
\totald{\mathcal{L}}{\mathbf{p}} = \int_{0}^{T}\left[
\partiald{\phi(\mathbf{s}, \mathbf{p}, t)}{\mathbf{p}} +
\lambda^T\partiald{\mathbf{f}}{\mathbf{p}}
\right]\mathrm{d}t +
\lambda^T\partiald{\mathbf{f}}{\mathbf{\dot{s}}}{\left(\partiald{\mathbf{g}}{\mathbf{s}(0)}\right)}^{-1}
\partiald{\mathbf{g}}{\mathbf{p}}
\end{equation}
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 16-11-2023</p>
<p class="author">Author: Mag√≠ Romany√† Serrasolsas</p>
</div>
</body>
</html>
